{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cea1eb-e73e-4d38-b10d-2e908d70e082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.llms.loading import load_llm\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature = 0.1,\n",
    "#     # streaming=True,\n",
    "#     # callbacks=[StreamingStdOutCallbackHandler()]\n",
    "# )\n",
    "\n",
    "# chat = OpenAI(\n",
    "#     temperature = 0.1,\n",
    "#     max_tokens=450,\n",
    "#     model=\"gpt-3.5-turbo-16k\",\n",
    "# )\n",
    "\n",
    "# chat.save(\"model.json\")\n",
    "\n",
    "# chat = load_llm(\"model.json\")\n",
    "\n",
    "# chat\n",
    "\n",
    "# t= PromptTemplate(\n",
    "#     template=\"What is the capital of {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# 위와 동일한 내용\n",
    "# t = PromptTemplate(template=\"What is the capital of {country}?\")\n",
    "\n",
    "# t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd41dec7-3bcc-48c2-988f-a63728dd3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "#     (\"human\", \"{recipe}\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca73f7cf-5272-4111-993d-a866591b71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and popular dish - Chicken Tikka Masala. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Chicken Tikka Masala\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons ground coriander\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon salt\n",
      "- 1 tablespoon vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated ginger\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, for garnish\n",
      "- Cooked rice or naan, for serving\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, paprika, garam masala, and salt. Add the chicken pieces and marinate for at least 1 hour, or overnight for best results.\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated chicken onto skewers and place them on a baking sheet. Bake for 20-25 minutes or until cooked through.\n",
      "3. In a large skillet, heat vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute.\n",
      "4. Stir in the crushed tomatoes and simmer for 10 minutes. Add the heavy cream and cooked chicken tikka pieces. Simmer for an additional 5-10 minutes.\n",
      "5. Garnish with fresh cilantro and serve hot with rice or naan.\n",
      "\n",
      "Enjoy your homemade Chicken Tikka Masala! Feel free to adjust the spice levels to suit your taste preferences.To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. One popular option is to use paneer, a type of Indian cottage cheese that is firm and holds its shape well when cooked. Here's how you can adapt the recipe:\n",
      "\n",
      "**Vegetarian Paneer Tikka Masala**\n",
      "\n",
      "**Ingredients:**\n",
      "- 1 lb paneer, cut into bite-sized cubes\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons ground coriander\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon salt\n",
      "- 1 tablespoon vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated ginger\n",
      "- 1 can (14 oz) crushed tomatoes\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, for garnish\n",
      "- Cooked rice or naan, for serving\n",
      "\n",
      "**Instructions:**\n",
      "1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, paprika, garam masala, and salt. Add the paneer cubes and marinate for at least 1 hour, or overnight for best results.\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated paneer cubes onto skewers and place them on a baking sheet. Bake for 15-20 minutes or until slightly browned.\n",
      "3. In a large skillet, heat vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute.\n",
      "4. Stir in the crushed tomatoes and simmer for 10 minutes. Add the heavy cream and cooked paneer tikka pieces. Simmer for an additional 5-10 minutes.\n",
      "5. Garnish with fresh cilantro and serve hot with rice or naan.\n",
      "\n",
      "Enjoy your vegetarian Paneer Tikka Masala! The paneer will absorb the flavors of the marinade and spices, making it a delicious and satisfying alternative to chicken."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. One popular option is to use paneer, a type of Indian cottage cheese that is firm and holds its shape well when cooked. Here's how you can adapt the recipe:\\n\\n**Vegetarian Paneer Tikka Masala**\\n\\n**Ingredients:**\\n- 1 lb paneer, cut into bite-sized cubes\\n- 1 cup plain yogurt\\n- 2 tablespoons lemon juice\\n- 2 teaspoons ground cumin\\n- 2 teaspoons ground coriander\\n- 1 teaspoon turmeric\\n- 1 teaspoon paprika\\n- 1 teaspoon garam masala\\n- 1 teaspoon salt\\n- 1 tablespoon vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1 tablespoon grated ginger\\n- 1 can (14 oz) crushed tomatoes\\n- 1 cup heavy cream\\n- Fresh cilantro, for garnish\\n- Cooked rice or naan, for serving\\n\\n**Instructions:**\\n1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, paprika, garam masala, and salt. Add the paneer cubes and marinate for at least 1 hour, or overnight for best results.\\n2. Preheat the oven to 400°F (200°C). Thread the marinated paneer cubes onto skewers and place them on a baking sheet. Bake for 15-20 minutes or until slightly browned.\\n3. In a large skillet, heat vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute.\\n4. Stir in the crushed tomatoes and simmer for 10 minutes. Add the heavy cream and cooked paneer tikka pieces. Simmer for an additional 5-10 minutes.\\n5. Garnish with fresh cilantro and serve hot with rice or naan.\\n\\nEnjoy your vegetarian Paneer Tikka Masala! The paneer will absorb the flavors of the marinade and spices, making it a delicious and satisfying alternative to chicken.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "# final_chain = {\"recipe\" : chef_chain} | veg_chain\n",
    "\n",
    "# final_chain.invoke({\n",
    "#     \"cuisine\": \"indian\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf16bcb1-ea97-408a-8f8b-85eae74d5031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "        I know the following:\n",
      "        Capital: Ankara\n",
      "        Language: Turkish\n",
      "        Food: Kebab and Baklava\n",
      "        Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI:\\n        I know the following:\\n        Capital: Ankara\\n        Language: Turkish\\n        Food: Kebab and Baklava\\n        Currency: Turkish Lira')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"question\": \"What do you know about France?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         Here is what I know:\n",
    "#         Capital: Paris\n",
    "#         Language: French\n",
    "#         Food: Wine and Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"question\": \"What do you know about Italy?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Rome\n",
    "#         Language: Italian\n",
    "#         Food: Pizza and Pasta\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"question\": \"What do you know about Greece?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Athens\n",
    "#         Language: Greek\n",
    "#         Food: Souvlaki and Feta Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# chat.predict(\"What do you know about France?\")\n",
    "\n",
    "# example_template = \"\"\"\n",
    "#     Human: {question}\n",
    "#     AI: {answer}\n",
    "# \"\"\"\n",
    "\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "# prompt = FewShotPromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     examples=examples,\n",
    "#     suffix=\"Human: What do you know about {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# prompt.format(country=\"Germany\")\n",
    "\n",
    "# chain = prompt | chat\n",
    "\n",
    "# chain.invoke({\"country\": \"Germany\"})\n",
    "# chain.invoke({\"country\": \"Turkey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "093b3e4a-c2c7-424d-a8d5-ce8f839894e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Bangkok\n",
      "        Language: Thai\n",
      "        Food: Pad Thai and Tom Yum Soup\n",
      "        Currency: Thai Baht"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Bangkok\\n        Language: Thai\\n        Food: Pad Thai and Tom Yum Soup\\n        Currency: Thai Baht')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"country\": \"France\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         Here is what I know:\n",
    "#         Capital: Paris\n",
    "#         Language: French\n",
    "#         Food: Wine and Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Italy\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Rome\n",
    "#         Language: Italian\n",
    "#         Food: Pizza and Pasta\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Greece\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Athens\n",
    "#         Language: Greek\n",
    "#         Food: Souvlaki and Feta Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# prompt = FewShotPromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     examples=examples,\n",
    "#     suffix=\"Human: What do you know about {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# chain = prompt | chat\n",
    "\n",
    "# chain.invoke({\"country\": \"Turkey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f089c7e-8935-4afe-a23e-7fd892ddd486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Italy?\\nAI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "# from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"question\": \"What do you know about France?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         Here is what I know:\n",
    "#         Capital: Paris\n",
    "#         Language: French\n",
    "#         Food: Wine and Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"question\": \"What do you know about Italy?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Rome\n",
    "#         Language: Italian\n",
    "#         Food: Pizza and Pasta\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"question\": \"What do you know about Greece?\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Athens\n",
    "#         Language: Greek\n",
    "#         Food: Souvlaki and Feta Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# class RandomExampleSelector(BaseExampleSelector):\n",
    "#     def __init__(self, examples):\n",
    "#         self.examples = examples\n",
    "\n",
    "#     def add_example(self, example):\n",
    "#         self.examples.append(example)\n",
    "\n",
    "#     def select_examples(self, input_variables):\n",
    "#         from random import choice\n",
    "\n",
    "#         return [choice(self.examples)]\n",
    "        \n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "# example_selector = LengthBasedExampleSelector(\n",
    "#     examples=examples,\n",
    "#     example_prompt=example_prompt,\n",
    "#     max_length=80\n",
    "# )\n",
    "\n",
    "# example_selector = RandomExampleSelector(\n",
    "#     examples=examples,\n",
    "# )\n",
    "\n",
    "# prompt = FewShotPromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     example_selector=example_selector,\n",
    "#     suffix=\"Human: What do you know about {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51792350-b0fe-4a86-899c-08bd9069b834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Colombia'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts import load_prompt\n",
    "\n",
    "# prompt=load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "# prompt.format(country=\"xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "203cd41a-1462-48c7-b51d-9263cb34bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrg matey! Me favorite food be a hearty stew made with fresh seafood and plenty of rum to wash it down with! Yarrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Arrg matey! Me favorite food be a hearty stew made with fresh seafood and plenty of rum to wash it down with! Yarrr!')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# intro = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     You are a role playing assistant. And you are impersonating a {character}.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# example = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     This is an example of how you talk:\n",
    "\n",
    "#     Human: {example_question}\n",
    "#     You: {example_answer}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# start = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     {intro}\n",
    "\n",
    "#     {example}\n",
    "\n",
    "#     Human: {question}\n",
    "#     You:\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# final = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     {intro}\n",
    "\n",
    "#     {example}\n",
    "\n",
    "#     {start}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# prompts = [\n",
    "#     (\"intro\", intro),\n",
    "#     (\"example\", example),\n",
    "#     (\"start\", start),\n",
    "# ]\n",
    "\n",
    "# full_prompt = PipelinePromptTemplate(\n",
    "#     final_prompt=final, \n",
    "#     pipeline_prompts=prompts\n",
    "# )\n",
    "\n",
    "# # full_prompt.format(\n",
    "# #     character=\"Pirate\",\n",
    "# #     example_question=\"What is your location?\",\n",
    "# #     example_answer=\"Arrg! That is a secret! Arg arg!!\",\n",
    "# #     question=\"What is ur fav food?\"\n",
    "# # )\n",
    "\n",
    "# chain = full_prompt | chat\n",
    "\n",
    "# chain.invoke({\n",
    "#     \"character\":\"Pirate\",\n",
    "#     \"example_question\":\"What is your location?\",\n",
    "#     \"example_answer\":\"Arrg! That is a secret! Arg arg!!\",\n",
    "#     \"question\":\"What is ur fav food?\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f8d4244-6710-4953-ab79-5f79241514d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make Italian pasta?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache()) # cache data\n",
    "# set_llm_cache(SQLiteCache(\"cache.db\")) # set cache and save it to database\n",
    "# set_debug(True) # show logs\n",
    "\n",
    "# chat.predict(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa1bbb7d-3433-4684-869f-488b636947dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll out each portion into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of salted boiling water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it answers immediately\n",
    "# chat.predict(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1df506bd-0dd4-4c7e-880a-2bbe88fb0e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with water until dissolved.\\n5. Add the cooked rice to the bowl and mix well.\\n6. Cover the bowl with a clean cloth and let it ferment in a warm place for 3-4 days.\\n7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\\n8. Transfer the liquid to a clean container and let it sit for another 1-2 days to allow the flavors to develop.\\n9. Serve the homemade soju chilled and enjoy responsibly.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with water until dissolved.\\n5. Add the cooked rice to the bowl and mix well.\\n6. Cover the bowl with a clean cloth and let it ferment in a warm place for 3-4 days.\\n7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\\n8. Transfer the liquid to a clean container and let it sit for another 1-2 days to allow the flavors to develop.\\n9. Serve the homemade soju chilled and enjoy responsibly.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for bread\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 3 1/2 cups all-purpose flour\\n- 1 packet active dry yeast\\n- 1 1/2 cups warm water\\n- 2 tablespoons sugar\\n- 1 teaspoon salt\\n- 2 tablespoons olive oil\\n\\nInstructions:\\n1. In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for about 5-10 minutes until the yeast is foamy.\\n2. Add the flour, salt, and olive oil to the yeast mixture. Mix until a dough forms.\\n3. Knead the dough on a floured surface for about 5-10 minutes until it is smooth and elastic.\\n4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1-2 hours or until doubled in size.\\n5. Punch down the dough and shape it into a loaf. Place the loaf in a greased loaf pan.\\n6. Cover the loaf with a clean towel and let it rise for another 30-45 minutes.\\n7. Preheat the oven to 375°F (190°C).\\n8. Bake the bread for 25-30 minutes or until golden brown and sounds hollow when tapped on the bottom.\\n9. Let the bread cool before slicing and serving. Enjoy!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 3 1/2 cups all-purpose flour\\n- 1 packet active dry yeast\\n- 1 1/2 cups warm water\\n- 2 tablespoons sugar\\n- 1 teaspoon salt\\n- 2 tablespoons olive oil\\n\\nInstructions:\\n1. In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for about 5-10 minutes until the yeast is foamy.\\n2. Add the flour, salt, and olive oil to the yeast mixture. Mix until a dough forms.\\n3. Knead the dough on a floured surface for about 5-10 minutes until it is smooth and elastic.\\n4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1-2 hours or until doubled in size.\\n5. Punch down the dough and shape it into a loaf. Place the loaf in a greased loaf pan.\\n6. Cover the loaf with a clean towel and let it rise for another 30-45 minutes.\\n7. Preheat the oven to 375°F (190°C).\\n8. Bake the bread for 25-30 minutes or until golden brown and sounds hollow when tapped on the bottom.\\n9. Let the bread cool before slicing and serving. Enjoy!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of water\n",
      "- 1 tablespoon of nuruk (fermentation starter)\n",
      "- 1 tablespoon of yeast\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\n",
      "2. Drain the rice and steam it until fully cooked.\n",
      "3. Let the rice cool down to room temperature.\n",
      "4. In a large bowl, mix the nuruk and yeast with water until dissolved.\n",
      "5. Add the cooked rice to the bowl and mix well.\n",
      "6. Cover the bowl with a clean cloth and let it ferment in a warm place for 3-4 days.\n",
      "7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\n",
      "8. Transfer the liquid to a clean container and let it sit for another 1-2 days to allow the flavors to develop.\n",
      "9. Serve the homemade soju chilled and enjoy responsibly. Ingredients:\n",
      "- 3 1/2 cups all-purpose flour\n",
      "- 1 packet active dry yeast\n",
      "- 1 1/2 cups warm water\n",
      "- 2 tablespoons sugar\n",
      "- 1 teaspoon salt\n",
      "- 2 tablespoons olive oil\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for about 5-10 minutes until the yeast is foamy.\n",
      "2. Add the flour, salt, and olive oil to the yeast mixture. Mix until a dough forms.\n",
      "3. Knead the dough on a floured surface for about 5-10 minutes until it is smooth and elastic.\n",
      "4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1-2 hours or until doubled in size.\n",
      "5. Punch down the dough and shape it into a loaf. Place the loaf in a greased loaf pan.\n",
      "6. Cover the loaf with a clean towel and let it rise for another 30-45 minutes.\n",
      "7. Preheat the oven to 375°F (190°C).\n",
      "8. Bake the bread for 25-30 minutes or until golden brown and sounds hollow when tapped on the bottom.\n",
      "9. Let the bread cool before slicing and serving. Enjoy! \n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# with get_openai_callback() as usage: \n",
    "#     a = chat.predict(\"What is the recipe for soju\")\n",
    "#     b = chat.predict(\"What is the recipe for bread\")\n",
    "#     print(a, b, \"\\n\")\n",
    "#     # print(usage)\n",
    "#     # print(usage.total_cost)\n",
    "#     # print(usage.total_tfrom langchain.llms.loading import load_llm\n",
    "# okens) # completion_tokens 도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc77c888-fa66-4e1e-8fd3-33f343cf36ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Memory\n",
    "\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory() # String 형식으로 출력\n",
    "# memory = ConversationBufferMemory(return_messages=True) # chat model 형식으로 출력\n",
    "\n",
    "# memory.save_context({\"input\":\"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "# memory.load_memory_variables({}) # 비효율적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1fbd86-3746-4725-902a-238ad4b74ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최근 n개 메세지만 저장 -> the most recent conversation\n",
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# memory = ConversationBufferWindowMemory(\n",
    "#     return_messages=True,\n",
    "#     k= 4, # 몇 개를 저장할지 설정\n",
    "# )\n",
    "\n",
    "# def add_message(input, output):\n",
    "#     memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "# add_message(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9639c85b-06c8-4fcb-86be-c13806d27685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(2,2)\n",
    "# add_message(3,3)\n",
    "# add_message(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a630f5f-8bff-4fe7-9727-0e663cbaa581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b760ff5-9c52-4d33-80c1-acef09b902ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c7f2a6-0f80-4bb3-9795-7190b9632b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({}) # (1,1) 이 사라진 것을 확인 가능 -> 이전 대화를 기억할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e320eb3-bb92-4c02-8201-da1bf1dd463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary -> useful for a very long conversation\n",
    "# 글자수가 많기 때문에 초반에는 더 많은 메모리와 토큰을 차지함\n",
    "# 그러나 대화가 진행될수록 저장된 메세지가 매우 많아지면서 모두 연결됨\n",
    "# 요약이 토큰 양을 줄일 수 있음 -> 더 효율적\n",
    "\n",
    "# from langchain.memory import ConversationSummaryMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# def add_message(input,output):\n",
    "#     memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "# add_message(\"Hi, I'm Camille. I live in South Korea.\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a49d0e2-257b-488a-8928-c6c1c1cfc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"South Korea is so pretty.\", \"I wish I could go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a33a261-9f00-4891-8f06-a13666e8d674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Camille introduces herself as living in South Korea, and the AI responds enthusiastically, calling it cool and expressing a wish to visit.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d0d06c-25ac-47f6-9a56-c7d6fcac647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\persona_ai\\git\\fullstack-gpt\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 893.9/893.9 kB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4964a1a1-aa02-4c7c-af97-1612c653162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 최근 메세지, 가장 오래된 메세지 모두 요약\n",
    "# window buffer memory + buffer window memory\n",
    "\n",
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=150, # 최대 토큰 수\n",
    "#     return_messages=True, # chat model\n",
    "# )\n",
    "\n",
    "# def add_message(input,output):\n",
    "#     memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "# add_message(\"Hi, I'm Camille. I live in South Korea.\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93194d8f-c903-4db1-8830-f648ab74f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm Camille. I live in South Korea.\"),\n",
       "  AIMessage(content='Wow that is so cool!')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b084735f-c406-4de5-a905-8e35e2fd4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"South Korea is so pretty.\", \"I wish I could go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c09746-866b-4ce3-a9bc-6961cf649402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm Camille. I live in South Korea.\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty.'),\n",
       "  AIMessage(content='I wish I could go!')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409fbd8e-12f8-4d9f-b242-1b4245e2c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"How far is Korea from Argentina?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03644869-113f-4ebc-b473-55de7db3b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm Camille. I live in South Korea.\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty.'),\n",
       "  AIMessage(content='I wish I could go!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f6b64b4-1a38-44b0-a101-e9a711d0dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"How far is Brazil from Argentina?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a70b027e-18ee-49dd-9b2c-224bf4762393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm Camille. I live in South Korea.\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty.'),\n",
       "  AIMessage(content='I wish I could go!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2032896b-2649-4cc8-9c92-77334feeb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"How far is Colombia from Argentina?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcb57f1-95bf-488e-ac27-c0e79fef57e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm Camille. I live in South Korea.\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty.'),\n",
       "  AIMessage(content='I wish I could go!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Colombia from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1c508f-521b-4b26-a946-94cce1a25ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"How far is China from Peru?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258c9003-6e1b-42f1-bb5c-520ee083a73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces herself as Camille and mentions she lives in South Korea.'),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty.'),\n",
       "  AIMessage(content='I wish I could go!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Colombia from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is China from Peru?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20fb8852-584d-4adf-a6c7-24b1a7166b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationKGMemory (Knowledge Graph)\n",
    "# 가장 중요한 것들만 뽑아내는 요약본 -> 대화에서 entity 추출\n",
    "\n",
    "# from langchain.memory import ConversationKGMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationKGMemory(\n",
    "#     llm=llm,\n",
    "#     return_messages=True, # chat model\n",
    "# )\n",
    "\n",
    "# def add_message(input,output):\n",
    "#     memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "# add_message(\"Hi, I'm Camille. I live in South Korea.\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71990c5a-3e0a-485e-b3ab-f11f2b564211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Camille: Camille lives in South Korea.')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({\"input\":\"who is Camille\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39439124-a281-4a88-bae0-08dcb90ec524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_message(\"Camille likes Kimchi\", \"Sounds delicious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f907f8b3-ca49-4bc4-8f2d-08b4adfa897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Camille: Camille lives in South Korea. Camille likes Kimchi.')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({\"input\":\"what does Camille like\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a23ee3a0-b195-4a11-937c-4895c4b9c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Camille! How can I assist you today?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memory on LLMChain\n",
    "# interaction의 토큰 수가 limit(80)보다 많으면 가장 오래된 interaction을 요약해줌\n",
    "\n",
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=80,\n",
    "#     # verbose=True, # log\n",
    "# )\n",
    "\n",
    "# chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     prompt=PromptTemplate.from_template(\"{question}\")\n",
    "# )\n",
    "\n",
    "# chain.predict(question=\"My name is Camille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37465a01-d319-477a-891e-d69973c804c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\", the capital city of South Korea. It is a bustling metropolis with a vibrant culture, delicious food, and a mix of modern skyscrapers and historic palaces. I love exploring the city's neighborhoods, trying new restaurants, and taking in the beautiful views of the Han River. Seoul is a dynamic and exciting place to call home.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ac7fe55-e0e3-473c-8b35-62a6b68bf2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"What's my name\") # it doesn't work -> history isn't added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bbe02d0-e033-4472-9826-b70208fd29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: My name is Camille\\nAI: Nice to meet you, Camille! How can I assist you today?\\nHuman: What's my name\\nAI: I'm sorry, I do not have access to personal information such as your name.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({}) # Update는 진행하지만 프롬프트에 그 히스토리를 반영하지 않는다 -> template 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46671d1d-9053-4238-b2fa-7b2c36f27a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Camille! How can I assist you today?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 먼저 메모리 객체 생성 (memory_key 설정 포함)\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=120,\n",
    "#     memory_key=\"chat_history\" # 템플릿에서 동일한 이름 사용해야 함\n",
    "# )\n",
    "\n",
    "# template = \"\"\"\n",
    "#     You are a helpful AI talking to a human. \n",
    "\n",
    "#     {chat_history}\n",
    "#     Human:{question}\n",
    "#     You:\n",
    "# \"\"\"\n",
    "\n",
    "# # 템플릿 적용\n",
    "# chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     prompt=PromptTemplate.from_template(template)\n",
    "# )\n",
    "\n",
    "# chain.predict(question=\"My name is Camille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88569369-da69-445f-8046-2f0243ba2c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great to know! How can I assist you with living in Seoul?\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"I live in Seoul\") # prompt가 history를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35fd7753-ef78-4926-82d8-5ead92a4b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Camille.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"What's my name\") # it remembers my name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb1d640a-5311-4bcc-8135-4ac552ffb4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: My name is Camille\\nAI: Hello Camille! How can I assist you today?\\nHuman: I live in Seoul\\nAI: That's great to know! How can I assist you with living in Seoul?\\nHuman: What's my name\\nAI: Your name is Camille.\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({}) # 텍스트 형식으로 출력됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63108b4b-4c73-42ee-8dd7-6d43ab437809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human\n",
      "Human: My name is Camille\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Camille! How can I assist you today?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat based memory: 대화 기반의 형식으로 받고 싶다면 \n",
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=120,\n",
    "#     memory_key=\"chat_history\",\n",
    "#     return_messages=True\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful AI talking to human\"),\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"), # 우리는 메세지가 얼마나 많고 누구로부터 왔는지 모름. 위의 memory class로 대체될 것.\n",
    "#     (\"human\", \"{question}\")\n",
    "# ])\n",
    "\n",
    "# chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     prompt=prompt,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# chain.predict(question=\"My name is Camille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16b13f0c-d2c2-4997-b952-3dbf82c5ce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human\n",
      "Human: My name is Camille\n",
      "AI: Hello Camille! How can I assist you today?\n",
      "Human: I live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "503aae30-7b4b-4ebd-b276-7f51e1b0aa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human\n",
      "Human: My name is Camille\n",
      "AI: Hello Camille! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?\n",
      "Human: What's my name\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Camille. How can I assist you further, Camille?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.predict(question=\"What's my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e4ea2c7-82ae-4d22-8ae6-2cb4ff1ae3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스터마이징 메모리: LCEL based Memory\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough # Prompt가 format 되기 전에 함수 실행시키는 걸 허락해준다\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory와 prompt는 변하지 않는다.\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to human\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"), # 우리는 메세지가 얼마나 많고 누구로부터 왔는지 모름. 위의 memory class로 대체될 것.\n",
    "    (\"human\", \"{question}\")\n",
    "]) \n",
    "\n",
    "def load_memory(_): # _: ignore\n",
    "    # print(input)\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "# 체인을 호출하는 함수 생성 -> 수동으로 메모리 관리하는 것보다 편리한 방법\n",
    "def invoke_chain(question): \n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\":question}, \n",
    "        {\"output\":result.content}\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82fb7199-b05f-4b51-b0a7-ce75930aab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello Camille! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is Camille\") #  대화 내용이 메모리에 저장되고, LLM은 이전 대화 내용을 기억하면서 응답함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d81f752e-077d-4334-b3b8-6d9549a8ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Camille.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"what is my name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
